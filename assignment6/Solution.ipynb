{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__ Train a convolutional neural network on the data. Find a good set of hyperparameters for the model. Do you think a convolutional neural network is suitable for this kind of problem? Why/why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import seed, randint\n",
    "\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15737, 62, 65, 1)\n",
      "(15737, 4)\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.load('/project/XSound.npy')\n",
    "Y = tf.keras.utils.to_categorical(np.load('/project/YSound.npy'))\n",
    "#Y = np.load('/project/YSound.npy')\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9441, 62, 65, 1)\n",
      "(9441, 4)\n",
      "(3148, 62, 65, 1)\n",
      "(3148, 4)\n",
      "(3148, 62, 65, 1)\n",
      "(3148, 4)\n"
     ]
    }
   ],
   "source": [
    "X_, X_test, Y_, Y_test = train_test_split(X, Y, train_size=.8, random_state=504)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_, Y_, train_size=.75, random_state=504)\n",
    "#X_train, y_train = train_test_split(X_train, Y_train)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 65, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 62, 65, 240)       2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 20, 21, 240)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_21 (Spatia (None, 20, 21, 240)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_18 (Averag (None, 10, 10, 240)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 10, 10, 120)       259320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_22 (Spatia (None, 10, 10, 120)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_19 (Averag (None, 5, 5, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 150)               450150    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 604       \n",
      "=================================================================\n",
      "Total params: 712,474\n",
      "Trainable params: 712,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights=True)\n",
    "\n",
    "cnn = tf.keras.models.Sequential([\n",
    "    layers.Conv2D(240, 3, activation='relu', padding='same', input_shape=X_train[0].shape),\n",
    "    layers.MaxPooling2D((3)),\n",
    "    layers.SpatialDropout2D(.4),\n",
    "    layers.AveragePooling2D(),\n",
    "    layers.Conv2D(120, 3, activation='relu', padding='same'),\n",
    "    layers.SpatialDropout2D(.4),\n",
    "    layers.AveragePooling2D(),\n",
    "    #layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "    #layers.SpatialDropout2D(.4),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=150, activation='relu'),\n",
    "    layers.Dropout(.4),\n",
    "    layers.Dense(units=4, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001), metrics = ['accuracy'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9441 samples, validate on 3148 samples\n",
      "Epoch 1/100\n",
      "9441/9441 [==============================] - 3s 312us/sample - loss: 1.5047 - accuracy: 0.2457 - val_loss: 1.4386 - val_accuracy: 0.2446\n",
      "Epoch 2/100\n",
      "9441/9441 [==============================] - 3s 296us/sample - loss: 1.3870 - accuracy: 0.2542 - val_loss: 1.4392 - val_accuracy: 0.2481\n",
      "Epoch 3/100\n",
      "9441/9441 [==============================] - 3s 292us/sample - loss: 1.3863 - accuracy: 0.2632 - val_loss: 1.4388 - val_accuracy: 0.2402\n",
      "Epoch 4/100\n",
      "9441/9441 [==============================] - 3s 288us/sample - loss: 1.3871 - accuracy: 0.2479 - val_loss: 1.4386 - val_accuracy: 0.2405\n",
      "Epoch 5/100\n",
      "9441/9441 [==============================] - 3s 287us/sample - loss: 1.3865 - accuracy: 0.2490 - val_loss: 1.4397 - val_accuracy: 0.2408\n",
      "Epoch 6/100\n",
      "9441/9441 [==============================] - 3s 292us/sample - loss: 1.3862 - accuracy: 0.2592 - val_loss: 1.4392 - val_accuracy: 0.2370\n",
      "Epoch 7/100\n",
      "9441/9441 [==============================] - 3s 286us/sample - loss: 1.3872 - accuracy: 0.2440 - val_loss: 1.4396 - val_accuracy: 0.2408\n",
      "Epoch 8/100\n",
      "9441/9441 [==============================] - 3s 297us/sample - loss: 1.3870 - accuracy: 0.2466 - val_loss: 1.4390 - val_accuracy: 0.2433\n",
      "Epoch 9/100\n",
      "9441/9441 [==============================] - 3s 299us/sample - loss: 1.3870 - accuracy: 0.2487 - val_loss: 1.4388 - val_accuracy: 0.2449\n",
      "Epoch 10/100\n",
      "9441/9441 [==============================] - 3s 370us/sample - loss: 1.3867 - accuracy: 0.2503 - val_loss: 1.4403 - val_accuracy: 0.2525\n",
      "Epoch 11/100\n",
      "9441/9441 [==============================] - 3s 371us/sample - loss: 1.3868 - accuracy: 0.2576 - val_loss: 1.4389 - val_accuracy: 0.2513\n",
      "Epoch 12/100\n",
      "9441/9441 [==============================] - 3s 352us/sample - loss: 1.3866 - accuracy: 0.2526 - val_loss: 1.4390 - val_accuracy: 0.2379\n",
      "Epoch 13/100\n",
      "9441/9441 [==============================] - 3s 319us/sample - loss: 1.3870 - accuracy: 0.2419 - val_loss: 1.4387 - val_accuracy: 0.2541\n",
      "Epoch 14/100\n",
      "9441/9441 [==============================] - 3s 302us/sample - loss: 1.3865 - accuracy: 0.2489 - val_loss: 1.4395 - val_accuracy: 0.2424\n"
     ]
    }
   ],
   "source": [
    "history = cnn.fit(X_train, Y_train, \n",
    "                    epochs = 100, \n",
    "                    validation_data=(X_valid, Y_valid),\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9441/9441 [==============================] - 1s 70us/sample - loss: 1.8409 - accuracy: 0.2449\n",
      "3148/3148 [==============================] - 0s 72us/sample - loss: 1.8256 - accuracy: 0.2456\n",
      "On train data: Loss = 1.8409, accuracy = 0.2449\n",
      "On test data: Loss = 1.8256, accuracy = 0.2456\n",
      "Error on test data: 75.44%\n"
     ]
    }
   ],
   "source": [
    "train_eval = cnn.evaluate(X_train[:9441], Y_train[:9441])\n",
    "test_eval = cnn.evaluate(X_test, Y_test)\n",
    "print(\"On train data: Loss = {loss:.4f}, accuracy = {accuracy:.4f}\".format(loss=train_eval[0], accuracy=train_eval[1]))\n",
    "print(\"On test data: Loss = {loss:.4f}, accuracy = {accuracy:.4f}\".format(loss=test_eval[0], accuracy=test_eval[1]))\n",
    "print(\"Error on test data: {p:.2f}%\".format(p = 100*(1-test_eval[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__ Classify instances of the test set using your models. Draw a confusion matrix and comment on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(c)__ Choose one other algorithm from the course, and redo (a) and (b) using this algorithm. Supply a brief discussion of why we would expect this algorithm to do better/worse than the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8835193682117054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=53613.36110051616)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "#lasso = Lasso(max_iter = 10000) # Standard scale pipeline will fix!\n",
    "#coefs = []\n",
    "\n",
    "X = np.load('/project/XSound.npy')\n",
    "#Y = tf.keras.utils.to_categorical(np.load('/project/YSound.npy'))\n",
    "Y = np.load('/project/YSound.npy')\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "\n",
    "X_df = pd.DataFrame(X.reshape(-1, 4030))\n",
    "Y_df = pd.DataFrame(Y)\n",
    "#print(Y_df.head)\n",
    "#print(X_df.head)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_df, Y_df, train_size=.8, random_state=0)\n",
    "#X_train_df = df = pd.DataFrame(X_train.reshape(-1, 4030))\n",
    "#Y_train_df = df = pd.DataFrame(Y_train)#.reshape(-1, len(Y_train)))\n",
    "#X_test_df = df = pd.DataFrame(X_test.reshape(-1, len(X_test)))\n",
    "#Y_test_df = df = pd.DataFrame(Y_test)#.reshape(-1, len(Y_test)))\n",
    "\n",
    "#print(X[0:1])\n",
    "#print(X_train.head)\n",
    "#print(Y[0:1])\n",
    "#print(Y_train.head)\n",
    "# Create a pipeline with StandardScaler and RidgeCV\n",
    "ridgecv = make_pipeline(StandardScaler(), RidgeCV(alphas=alphas, scoring='neg_mean_squared_error'))\n",
    "ridgecv.fit(X_train, Y_train)\n",
    "\n",
    "# Access the chosen alpha value from RidgeCV\n",
    "chosen_alpha = ridgecv.named_steps['ridgecv'].alpha_\n",
    "#print(chosen_alpha)\n",
    "# Some of the coefficients\n",
    "# \n",
    "# # Create a Ridge model using the chosen alpha from RidgeCV\n",
    "ridge_model = Ridge(alpha=ridgecv.named_steps['ridgecv'].alpha_)\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "\n",
    "# Calculate the test MSE using the trained Ridge model\n",
    "mse = mean_squared_error(Y_test, ridge_model.predict(X_test))\n",
    "print(mse) \n",
    "ridge_model.fit(X_df, Y_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment6",
   "language": "python",
   "name": "assignment6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
