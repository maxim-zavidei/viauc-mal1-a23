{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e731acc",
   "metadata": {},
   "source": [
    "## Speech recognition\n",
    "\n",
    "__You should be able to do this exercise after Lecture 9.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edffe2f",
   "metadata": {},
   "source": [
    "In this exercise, we will work with the <a href=\"https://arxiv.org/pdf/1804.03209.pdf\">Google Speech Command Dataset</a>, which can be downloaded from <a href=\"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\">here</a> (note: you do not need to download the full dataset, but it will allow you to play around with the raw audiofiles). This dataset contains 105,829 one-second long audio files with utterances of 35 common words.\n",
    "\n",
    "We will use a subset of this dataset as indicated in the table below.\n",
    "\n",
    "| Word | How many? | Class # |\n",
    "| :-: | :-: | :-: |\n",
    "| Yes | 4,044 | 3 |\n",
    "| No | 3,941 | 1 |\n",
    "| Stop | 3,872 | 2 |\n",
    "| Go | 3,880 | 0 |\n",
    "\n",
    "The data is given in the files `XSound.npy` and `YSound.npy`, both of which can be imported using `numpy.load`. `XSound.npy` contains spectrograms (_e.g._, matrices with a time-axis and a frequency-axis of size 62 (time) x 65 (frequency)). `YSound.npy` contains the class number, as indicated in the table above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18752ccd",
   "metadata": {},
   "source": [
    "__(a)__ Train a convolutional neural network on the data. Find a good set of hyperparameters for the model. Do you think a convolutional neural network is suitable for this kind of problem? Why/why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7de29",
   "metadata": {},
   "source": [
    "__(b)__ Classify instances of the test set using your models. Draw a confusion matrix and comment on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df69fef",
   "metadata": {},
   "source": [
    "__(c)__ Choose one other algorithm from the course, and redo (a) and (b) using this algorithm. Supply a brief discussion of why we would expect this algorithm to do better/worse than the CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
